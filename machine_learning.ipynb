{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "### Modelado\n",
    "\n",
    "- Para nuestro Sistema de Recomendacion utilizamos los filtros basados en contenido (contend-based filtering) como base de la prediccion, es decir, que sugiere películas similares basados en una películas en particular.\n",
    "\n",
    "- En este sistema, las caracteristicas de las películas (overview, genre, company, actor) se usan para encontrar su similitud con otras películas. Luego se recomiendan 5 películas que tienen más probabilidades de ser similares a la consultada en nuestra API.\n",
    "\n",
    "- El procesamiento del lenguaje natural (NLP) es un proceso de manipulación o comprensión del texto por cualquier software o máquina.\n",
    "\n",
    "- Utilizamos La biblioteca NLTK (Natural Language Toolkit), la cual es una suite que contiene bibliotecas para el procesamiento estadístico del lenguaje, y de esta forma hacer que las máquinas entiendan el lenguaje humano y respondan con una respuesta adecuada.\n",
    "\n",
    "- Tambien utilizamos RAKE, el cual es un algoritmo de extracción de palabras clave en un cuerpo de texto mediante el análisis de la frecuencia de aparición de palabras y su co-ocurrencia con otras palabras en el texto.\n",
    "\n",
    "- Utilizamos el Stemming, es una técnica de normalización de texto en el procesamiento del lenguaje natural. Esta técnicas es ampliamente utilizadas para el preprocesamiento de texto. Es una técnica en la que un conjunto de palabras en una oración se convierten en una secuencia para acortar su búsqueda. En este método, se normalizan las palabras que tienen el mismo significado pero tienen algunas variaciones según el contexto o la oración.\n",
    "\n",
    "- Como métrica utilizamos Cosine Similarity, la cual determina cuán similares son los objetos de datos independientemente de su tamaño. En la similitud del coseno, los objetos de datos en un conjunto de datos se tratan como un vector.\n",
    "\n",
    "- La similitud de coseno es beneficiosa para las aplicaciones que utilizan datos dispersos, como documentos de texto, transacciones en datos de mercado y sistemas de recomendación porque la similitud de coseno ignora las coincidencias 0-0. Contar coincidencias 0-0 en datos escasos inflaría las puntuaciones de similitud.\n",
    "\n",
    "- Para calcular la similitud del coseno, necesitamos el número de palabras de cada observacion de la columna 'tags'. Para realizar estos calculos utilizamos CountVectorizer de Sklearn para aprender el vocabulario del conjunto de textos y luego transformarlos en un marco de datos que utilizamos para construir el modelo. Este proceso nos da como salida una matriz dispersa 'sparse_matrix', la cual utilizamons en cosine_similarity() y asi obtener el resultado final.\n",
    "\n",
    "- Adicionalmente creamos una serie con los indices de cada una de de las peliculas.\n",
    "\n",
    "- En nuestra funcion de recomendacion, pasamos como parametros el titulo de la pelicula que deseamos, y tambien la variable cosine_sim. Se realiza la busqueda del titulo en el archivo de indices, el indice de la misma es buscado en cosine_sim y nos da como resultado una lista de las 5 peliculas similares, dependiendo del score de la pelicula consultada. Si la pelicula no se encuentra en el set de datos, retorna una notificacion.\n",
    "\n",
    "### Observaciones\n",
    "- La calidad y cantidad de los datos es de suma importancia. Un buen algoritmo con datos de poca calidad ofrecerá asimismo recomendaciones de baja calidad. Pero unos buenos datos, con el volumen suficiente y organizados eficientemente, nos darán recomendaciones razonablemente buenas aunque el algoritmo no sea óptimo.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\58424\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\58424\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rake_nltk\n",
    "from rake_nltk import Rake\n",
    "import nltk #Natural Language ToolKit\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer #para convertir las caracteristicas combinadas en una matriz\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el dataset\n",
    "movies = pd.read_csv('datasets/movies.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizamos la libreria Rake para extraer las palabras claves de cada película, de la columna 'overview'. Creamos la columna 'words' para almacenar las palabras extraídas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['words'] = \"\"\n",
    "\n",
    "for index, row in movies.iterrows():\n",
    "    r = Rake()  #Instancia de Rake\n",
    "    overview = row['overview']\n",
    "    r.extract_keywords_from_text(overview)  #Metodo para extraer palabras\n",
    "    score_words = r.get_word_degrees()    #Diccionario con las palabras claves y sus puntuaciones\n",
    "    movies.at[index, 'words'] = list(score_words.keys()) #Asignamos las palabras claves a la columna words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genre'].str.split(',')\n",
    "movies['companies'] = movies['company'].str.split(',')\n",
    "movies['actors'] = movies['actor'].str.split(',')\n",
    "\n",
    "#Remplazamos los valos \" \" por \"\" en cada una de las listas de las columnas desanidadas\n",
    "movies['genres'] = movies['genres'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['companies'] = movies['companies'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['actors'] = movies['actors'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "\n",
    "#Creamos una columna que reuna los datos de las columnas que usamos para alimentar el modelo\n",
    "movies['tags'] = movies['words'] + movies['genres'] + movies['companies'] + movies['actors']\n",
    "\n",
    "# Se dejan unicamente la columna 'tags' en el modelo puesto que es la unica que se va a ausar para la alimentacion del modelo\n",
    "movies = movies[['title','tags']]\n",
    "\n",
    "# unimos todas las cadenas en una sola, con respecto a la columna 'tags'\n",
    "movies['tags'] = movies['tags'].apply(lambda x:' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementacion de la libreria para normalizar la columna 'tags'\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def normalization(text):\n",
    "    tag = []\n",
    "    for i in text.split():\n",
    "        tag.append(ps.stem(i))\n",
    "    return \" \".join(tag)\n",
    "\n",
    "# aplicamos la funcion sobre la columana 'tags'\n",
    "movies['tags'] = movies['tags'].apply(normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_csv('datasets/moviesML.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.05484543 0.02299002 ... 0.         0.04767313 0.        ]\n",
      " [0.05484543 1.         0.01849317 ... 0.01849317 0.01917412 0.        ]\n",
      " [0.02299002 0.01849317 1.         ... 0.         0.09644856 0.03569722]\n",
      " ...\n",
      " [0.         0.01849317 0.         ... 1.         0.02411214 0.        ]\n",
      " [0.04767313 0.01917412 0.09644856 ... 0.02411214 1.         0.01850583]\n",
      " [0.         0.         0.03569722 ... 0.         0.01850583 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer  = CountVectorizer()\n",
    "sparse_matrix  = count_vectorizer .fit_transform(movies['tags'])\n",
    "cosine_sim = cosine_similarity(sparse_matrix , sparse_matrix)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m indices \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(movies[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m indices\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mdatasets/indices.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m cosine_sim\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39m\u001b[39mdatasets/cosine_sim.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "indices = pd.Series(movies['title'])\n",
    "indices.to_csv('datasets/indices.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion(titulo, cosine_sim = cosine_sim):\n",
    "\n",
    "    title=titulo.lower()\n",
    "\n",
    "    #Validar que el titulo ingresado se encuentra en el dataframe\n",
    "    if titulo not in movies['title'].values:\n",
    "        return 'Pelicula no encontrada!'\n",
    "    else:\n",
    "        list_movies = []\n",
    "        idx = indices[indices == titulo].index[0]\n",
    "        score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "        top_5_indices = list(score_series.iloc[1:6].index)\n",
    "        \n",
    "        for i in top_5_indices:\n",
    "            list_movies.append(list(movies['title'])[i])\n",
    "            \n",
    "        return list_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cars 3', 'cars 2', \"a bug's life\", 'monsters, inc.', 'monsters university']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batman & robin',\n",
       " 'batman forever',\n",
       " 'batman returns',\n",
       " 'the lego batman movie',\n",
       " 'batman: mask of the phantasm']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('batman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dracula 2000',\n",
       " 'van helsing',\n",
       " \"it's alive\",\n",
       " \"mary shelley's frankenstein\",\n",
       " 'vampire in brooklyn']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('dracula')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jurassic world',\n",
       " 'the lost world: jurassic park',\n",
       " 'scooby-doo',\n",
       " 'zathura: a space adventure',\n",
       " 'rumble fish']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('jurassic park')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superman ii',\n",
       " 'superman iv: the quest for peace',\n",
       " 'superman iii',\n",
       " 'superman returns',\n",
       " 'max steel']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('superman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toy story 2', 'toy story 3', 'free birds', \"a bug's life\", 'monsters, inc.']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('toy story')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hotel transylvania 2',\n",
       " 'grown ups',\n",
       " 'monster house',\n",
       " 'grown ups 2',\n",
       " 'the croods']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('hotel transylvania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the empire strikes back',\n",
       " 'return of the jedi',\n",
       " 'star wars: the force awakens',\n",
       " 'star wars: episode iii - revenge of the sith',\n",
       " 'star wars: episode i - the phantom menace']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('star wars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformers: revenge of the fallen',\n",
       " 'transformers: dark of the moon',\n",
       " 'transformers: age of extinction',\n",
       " 'transformers: the last knight',\n",
       " 'double dragon']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['back to the future part ii',\n",
       " 'back to the future part iii',\n",
       " 'spacecamp',\n",
       " 'honey, i shrunk the kids',\n",
       " 'hot tub time machine']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('back to the future')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
