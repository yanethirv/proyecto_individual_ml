{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "- Para nuestro Sistema de Recomendacion utilizamos los filtros basados en contenido (contend-based filtering) como base de la prediccion, es decir, que sugiere películas similares basados en una películas en particular.\n",
    "\n",
    "- En este sistema, las caracteristicas de las películas (overview, genre, company, actor) se usan para encontrar su similitud con otras películas. Luego se recomiendan 5 películas que tienen más probabilidades de ser similares a la consultada en nuestra API.\n",
    "\n",
    "- El procesamiento del lenguaje natural (NLP) es un proceso de manipulación o comprensión del texto por cualquier software o máquina.\n",
    "\n",
    "- Utilizamos La biblioteca NLTK (Natural Language Toolkit), la cual es una suite que contiene bibliotecas para el procesamiento estadístico del lenguaje, y de esta forma hacer que las máquinas entiendan el lenguaje humano y respondan con una respuesta adecuada.\n",
    "\n",
    "- También utilizamos RAKE, el cual es un algoritmo de extracción de palabras clave en un cuerpo de texto mediante el análisis de la frecuencia de aparición de palabras y su co-ocurrencia con otras palabras en el texto.\n",
    "\n",
    "- Utilizamos el Stemming, es una técnica de normalización de texto en el procesamiento del lenguaje natural. Esta técnica es ampliamente utilizadas para el preprocesamiento de texto. Es una técnica en la que un conjunto de palabras en una oración se convierten en una secuencia para acortar su búsqueda. En este método, se normalizan las palabras que tienen el mismo significado pero tienen algunas variaciones según el contexto o la oración.\n",
    "\n",
    "-  Para nuestro modelo utilizamos la técnica k-Nearest Neighbor (**Knn**), mejor conocido como el método de vecinos más cercanos, para definir las recomendaciones, es un método de clasificación no paramétrico, la cual determina cuán similares son los objetos de datos independientemente de su tamaño.\n",
    "\n",
    "-  Para calcular los (**Knn**), necesitamos el número de palabras de cada observacion de la columna 'tags'. Para realizar estos cálculos utilizamos CountVectorizer de Sklearn para aprender el vocabulario del conjunto de textos y luego transformarlos en un marco de datos que utilizamos para construir el modelo. Este proceso nos da como salida una matriz de correlaciones, luego define una matriz de distancia por medio de la matriz de correlaciones, y se aplica el método Knn, el cual realizará  la estimación.\n",
    "\n",
    "-  Adicionalmente creamos una serie con los índices de cada una de de las películas , la cual utilizaremos en nuestra estimacion.\n",
    "\n",
    "-  En nuestra función de recomendación, pasamos como parámetros el titulo de la películas que deseamos consular. Se realiza la búsqueda del titulo en el archivo de índices, el índice de la misma es buscado por (**Knn**), se obtiene una matriz la cual permite conocer cuales son las películas con mayor probabilidad para poder recomendarlas al usuario. La última línea muestra las 5 películas con mayor probabilidad de recomendar al usuario 1. Si la película no se encuentra en el set de datos, retorna una notificación.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\58424\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\58424\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import rake_nltk\n",
    "from rake_nltk import Rake\n",
    "import nltk #Natural Language ToolKit\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer #para convertir las caracteristicas combinadas en una matriz\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el dataset\n",
    "movies = pd.read_csv('datasets/movies.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Utilizamos la libreria Rake para extraer las palabras claves de cada película, de la columna 'overview'. Creamos la columna 'words' para almacenar las palabras extraídas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['words'] = \"\"\n",
    "\n",
    "for index, row in movies.iterrows():\n",
    "    r = Rake()  #Instancia de Rake\n",
    "    overview = row['overview']\n",
    "    r.extract_keywords_from_text(overview)  #Metodo para extraer palabras\n",
    "    score_words = r.get_word_degrees()    #Diccionario con las palabras claves y sus puntuaciones\n",
    "    movies.at[index, 'words'] = list(score_words.keys()) #Asignamos las palabras claves a la columna words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\58424\\AppData\\Local\\Temp\\ipykernel_17876\\4184650190.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  moviesML['tags'] = moviesML['tags'].apply(lambda x:' '.join(x))\n"
     ]
    }
   ],
   "source": [
    "movies['genres'] = movies['genre'].str.split(',')\n",
    "movies['companies'] = movies['company'].str.split(',')\n",
    "movies['actors'] = movies['actor'].str.split(',')\n",
    "\n",
    "#Remplazamos los valos \" \" por \"\" en cada una de las listas de las columnas desanidadas\n",
    "movies['genres'] = movies['genres'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['companies'] = movies['companies'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['actors'] = movies['actors'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "\n",
    "#Creamos una columna que reuna los datos de las columnas que usamos para alimentar el modelo\n",
    "movies['tags'] = movies['words'] + movies['genres'] + movies['companies'] + movies['actors']\n",
    "\n",
    "# Se dejan unicamente la columna 'tags' en el modelo puesto que es la unica que se va a ausar para la alimentacion del modelo\n",
    "moviesML = movies[['title','tags']]\n",
    "\n",
    "# unimos todas las cadenas en una sola, con respecto a la columna 'tags'\n",
    "moviesML['tags'] = moviesML['tags'].apply(lambda x:' '.join(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Utilizamos el Stemming, es una técnica de normalización de texto en el procesamiento del lenguaje natural. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\58424\\AppData\\Local\\Temp\\ipykernel_17876\\4101395328.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  moviesML['tags'] = moviesML['tags'].apply(normalization)\n"
     ]
    }
   ],
   "source": [
    "# Implementacion de la libreria para normalizar la columna 'tags'\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def normalization(text):\n",
    "    tag = []\n",
    "    for i in text.split():\n",
    "        tag.append(ps.stem(i))\n",
    "    return \" \".join(tag)\n",
    "\n",
    "# aplicamos la funcion sobre la columana 'tags'\n",
    "moviesML['tags'] = moviesML['tags'].apply(normalization)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Exportamos a un archivo .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesML.to_csv('datasets/moviesML.csv', index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Para calcular los (**Knn**), necesitamos el número de palabras de cada observacion de la columna 'tags'. Para realizar estos cálculos utilizamos CountVectorizer de Sklearn para aprender el vocabulario del conjunto de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer  = CountVectorizer()\n",
    "sparse_matrix  = count_vectorizer.fit_transform(moviesML['tags'])\n",
    "\n",
    "# Creamos un modelo para encontrar los vecinos mas cercanos en un espacio de caracterisicaa\n",
    "nn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "nn.fit(sparse_matrix)\n",
    "\n",
    "indicesML = pd.Series(moviesML.index, index=moviesML['title']).drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Función de Recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion(titulo):\n",
    "\n",
    "    title=titulo.lower()\n",
    "\n",
    "    #Validar que el titulo ingresado se encuentra en el dataframe\n",
    "    if title not in moviesML['title'].values:\n",
    "        return 'Película no encontrada! Prueba con: Star Wars, Back to the Future, Dracula, Cars, Batman, Superman, Toy Story'\n",
    "    else:\n",
    "        # Si el título esta en el df, encuentra su indice\n",
    "        index = indicesML[title]\n",
    "\n",
    "        # Obtiene las puntuaciones de similitud de las 5 peliculas más cercanas\n",
    "        distances, indices_knn = nn.kneighbors(sparse_matrix[index], n_neighbors=6)  # indica que queremos encontrar las 6 peliculas más similares, incluyendo la pelicula dada\n",
    "\n",
    "        # Obtiene los indices de las peliculas\n",
    "        movie_indices = indices_knn[0][1:]  # Se omite el primer indice (la pelicula misma) con [1:]\n",
    "\n",
    "        # Devuelve las 5 peliculas mas similares\n",
    "        return moviesML['title'].iloc[movie_indices].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cars 3', 'cars 2', \"a bug's life\", 'monsters, inc.', 'monsters university']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batman & robin',\n",
       " 'batman forever',\n",
       " 'batman returns',\n",
       " 'the lego batman movie',\n",
       " 'batman: mask of the phantasm']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('batman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dracula 2000',\n",
       " 'van helsing',\n",
       " \"it's alive\",\n",
       " \"mary shelley's frankenstein\",\n",
       " 'vampire in brooklyn']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('dracula')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jurassic world',\n",
       " 'the lost world: jurassic park',\n",
       " 'scooby-doo',\n",
       " 'zathura: a space adventure',\n",
       " 'rumble fish']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('jurassic park')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superman ii',\n",
       " 'superman iv: the quest for peace',\n",
       " 'superman iii',\n",
       " 'superman returns',\n",
       " 'max steel']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('superman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toy story 2', 'toy story 3', 'free birds', \"a bug's life\", 'monsters, inc.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('toy story')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hotel transylvania 2',\n",
       " 'grown ups',\n",
       " 'monster house',\n",
       " 'grown ups 2',\n",
       " 'the croods']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('hotel transylvania')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the empire strikes back',\n",
       " 'return of the jedi',\n",
       " 'star wars: the force awakens',\n",
       " 'star wars: episode iii - revenge of the sith',\n",
       " 'star wars: episode i - the phantom menace']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('star wars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformers: revenge of the fallen',\n",
       " 'transformers: dark of the moon',\n",
       " 'transformers: age of extinction',\n",
       " 'transformers: the last knight',\n",
       " 'double dragon']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['back to the future part ii',\n",
       " 'back to the future part iii',\n",
       " 'spacecamp',\n",
       " 'honey, i shrunk the kids',\n",
       " 'hot tub time machine']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendacion('back to the future')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
